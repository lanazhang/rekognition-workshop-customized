{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object and image properties detection using Amazon Rekognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook provides a walkthrough of [object detection API](https://docs.aws.amazon.com/rekognition/latest/dg/labels.html) in Amazon Rekognition to identify objects.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Notebook\n",
    "import boto3\n",
    "from IPython.display import HTML, display, Image as IImage\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import time\n",
    "import os\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "# variables\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "awsRegion = boto3.session.Session().region_name\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "rekognition = boto3.client('rekognition')\n",
    "\n",
    "\n",
    "print(f\"SageMaker role is: {role}\\nDefault SageMaker Bucket: s3://{data_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect objects in image\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![object-detection-sample](../datasets/cars.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_s3_key = 'content-moderation-im/image-moderation/cars.jpg'\n",
    "s3.upload_file('../datasets/cars.jpg', data_bucket, image_s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Call Rekognition to detect objects in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Amazon Rekognition to detect objects in the image\n",
    "# https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectLabels.html\n",
    "\n",
    "detectLabelsResponse = rekognition.detect_labels(\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': data_bucket,\n",
    "            'Name': image_s3_key,\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review the raw JSON reponse from Rekognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show JSON response returned by Rekognition Labels API (Object Detection)\n",
    "# In the JSON response below, you will see Label, detected instances, confidence score and additional information.\n",
    "\n",
    "display(detectLabelsResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display list of detected unsafe objects}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaggedObjects = [\"Car\"]\n",
    "\n",
    "for label in detectLabelsResponse[\"Labels\"]:\n",
    "    if(label[\"Name\"] in flaggedObjects):\n",
    "        print(\"Detected unsafe object:\")\n",
    "        print(\"- {} (Confidence: {})\".format(label[\"Name\"], label[\"Confidence\"]))\n",
    "        print(\"  - Parents: {}\".format(label[\"Parents\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The code snippets below demonstrate how to use an open-source computer vision library, Pillow, to draw bounding box overlays on images. This allows you to visualize the location of an object in an image by highlighting the area with a box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will display image with bounded boxes around recognized objects\n",
    "# We will call this function in next step\n",
    "  \n",
    "def drawBoundingBoxes (sourceImage, boxes):\n",
    "    # blue, green, red, grey\n",
    "    colors = ((255,255,255),(255,255,255),(76,182,252),(52,194,123))\n",
    "    \n",
    "    # Download image locally\n",
    "    #imageLocation = tempFolder+os.path.basename(sourceImage)\n",
    "    imageLocation = sourceImage\n",
    "    #s3.download_file(bucketName, sourceImage, imageLocation)\n",
    "\n",
    "    # Draws BB on Image\n",
    "    bbImage = Image.open(imageLocation)\n",
    "    draw = ImageDraw.Draw(bbImage)\n",
    "    width, height = bbImage.size\n",
    "    col = 0\n",
    "    maxcol = len(colors)\n",
    "    line= 3\n",
    "    for box in boxes:\n",
    "        x1 = int(box[1]['Left'] * width)\n",
    "        y1 = int(box[1]['Top'] * height)\n",
    "        x2 = int(box[1]['Left'] * width + box[1]['Width'] * width)\n",
    "        y2 = int(box[1]['Top'] * height + box[1]['Height']  * height)\n",
    "        \n",
    "        draw.text((x1,y1),box[0],colors[col])\n",
    "        for l in range(line):\n",
    "            draw.rectangle((x1-l,y1-l,x2+l,y2+l),outline=colors[col])\n",
    "        col = (col+1)%maxcol\n",
    "    \n",
    "    imageFormat = \"PNG\"\n",
    "    ext = sourceImage.lower()\n",
    "    if(ext.endswith('jpg') or ext.endswith('jpeg')):\n",
    "        imageFormat = 'JPEG'\n",
    "\n",
    "    bbImage.save(imageLocation,format=imageFormat)\n",
    "\n",
    "    display(bbImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image and bounded boxes around detected objects\n",
    "boxes = []\n",
    "objects = detectLabelsResponse['Labels']\n",
    "for obj in objects:\n",
    "    for einstance in obj[\"Instances\"]:\n",
    "        boxes.append ((obj['Name'], einstance['BoundingBox']))\n",
    "    \n",
    "drawBoundingBoxes(\"../datasets/cars.jpg\", boxes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Amazon Rekognition Image returns information about image quality (sharpness, brightness, and contrast) for the entire image. Sharpness and brightness are also returned for the foreground and background of the image. Image Properties can also be used to detect dominant colors of the entire image, foreground, background, and objects with bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image-property-detection-sample](../datasets/green_car.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_property_s3_key = 'content-moderation-im/image-moderation/green_car.jpeg'\n",
    "s3.upload_file('../datasets/cars.jpg', data_bucket, image_property_s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePropertiesResponse = rekognition.detect_labels(\n",
    "    Image={\n",
    "        'S3Object': {\n",
    "            'Bucket': data_bucket,\n",
    "            'Name': image_property_s3_key,\n",
    "        }\n",
    "    },\n",
    "    Features=[\"IMAGE_PROPERTIES\"], # 'GENERAL_LABELS',\n",
    "    Settings={\n",
    "        \"ImageProperties\": {\n",
    "            \"MaxDominantColors\": 10\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show JSON response returned by Rekognition Labels API (Object Detection)\n",
    "# In the JSON response below, you will see Image Properties, sharpness, brightness, contrast and additional information.\n",
    "\n",
    "display(imagePropertiesResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image size and DPI (Dots per Inch) using Pillow\n",
    "im = Image.open('../datasets/green_car.jpeg')\n",
    "print(f'Image size: {im.size[0]} X {im.size[1]}')\n",
    "print(f'DPI: {im.info[\"dpi\"]}')\n",
    "\n",
    "# Image quality from Rekognition\n",
    "print('Quality: ')\n",
    "print(f'     Brightness: {round(imagePropertiesResponse[\"ImageProperties\"][\"Quality\"][\"Brightness\"],2)}%')\n",
    "print(f'     Sharpness: {round(imagePropertiesResponse[\"ImageProperties\"][\"Quality\"][\"Sharpness\"],2)}%')\n",
    "print(f'     Contrast: {round(imagePropertiesResponse[\"ImageProperties\"][\"Quality\"][\"Contrast\"],2)}%')\n",
    "\n",
    "print('Dominant Colors: ')\n",
    "for c in imagePropertiesResponse[\"ImageProperties\"][\"DominantColors\"]:\n",
    "    html = f'''<div style=\"background-color:{c['HexCode']};width:250px;margin-left:60px;padding-left:5px;\">RGB({c['Red']},{c['Green']},{c['Blue']}])  {round(c[\"PixelPercent\"],2)}%</div>'''\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn more about building an end to end worker safety app\n",
    "To learn on how to build an end to end worker safety app, learn more at https://github.com/aws-samples/aws-deeplens-worker-safety-project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### References\n",
    "- https://docs.aws.amazon.com/rekognition/latest/dg/API_DetectLabels.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/dg/API_StartLabelDetection.html\n",
    "- https://docs.aws.amazon.com/rekognition/latest/dg/API_GetLabelDetection.html\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully used Amazon Rekognition to identify specific objects in images and videos. In the next module,nyou will learn how to recognize explicit, suggestive or violent content in the images and videos."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
